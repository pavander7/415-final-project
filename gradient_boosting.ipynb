{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ad2546c-6820-426f-8a79-6f2452d7591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I: Standard library imports\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# II: Third-party imports\n",
    "\n",
    "# II.A: General utilities\n",
    "import holidays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# II.B: Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# III: Machine learning\n",
    "\n",
    "# III.A: Scikit-learn\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, BaseCrossValidator, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# III.B: TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D, Dense, Dropout, Flatten, Input, Lambda, LSTM, MaxPooling1D\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# III.C: XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# III.D: Time-series specific models\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# IV: Local imports\n",
    "from pauls_data_loaders import loader_functions as lf\n",
    "\n",
    "# V: Global config options\n",
    "\n",
    "# Silence TensorFlow messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Pandas display options\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc617b35",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054fc3e1",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c154339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag_features(df, column, lags):\n",
    "    for lag in lags:\n",
    "        df[f\"{column}_lag_{lag}\"] = df[column].shift(lag)\n",
    "    return df\n",
    "\n",
    "def add_rolling_avg_features(df, column, windows):\n",
    "    for window in windows:\n",
    "        df[f\"{column}_rolling_avg_{window}\"] = df[column].rolling(window).mean()\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def add_time_features(df):\n",
    "    \"\"\"\n",
    "    Adds time-based features to the dataframe based on the index (assumed to be datetime).\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input dataframe.\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with time-based features added.\n",
    "    \"\"\"\n",
    "    # Ensure the index is datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df.index):\n",
    "        raise ValueError(\"Index must be of datetime type\")\n",
    "    \n",
    "    # Extracting features from datetime index\n",
    "    df['hour'] = df.index.hour  # Hour of the day\n",
    "    df['day_of_week'] = df.index.dayofweek  # Day of the week (0 = Monday, 6 = Sunday)\n",
    "    df['month'] = df.index.month  # Month (1 = January, 12 = December)\n",
    "    df['quarter'] = df.index.quarter  # Quarter of the year (1-4)\n",
    "    df['year'] = df.index.year  # Year\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f730ce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_engineered_features(df, config, standardize_columns=None):\n",
    "    \"\"\"\n",
    "    Adds engineered features, holiday flags, and standardizes specified columns.\n",
    "    Assumes that datetime is always the index column.\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input dataframe.\n",
    "        config (dict): Configuration dictionary with feature parameters.\n",
    "        standardize_columns (list): List of columns to standardize.\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with standardized columns and engineered features.\n",
    "    \"\"\"\n",
    "    # Standardize specified columns\n",
    "    if standardize_columns:\n",
    "        scaler = StandardScaler()\n",
    "        df[standardize_columns] = scaler.fit_transform(df[standardize_columns])\n",
    "\n",
    "    # Add lag features\n",
    "    if \"lag\" in config:\n",
    "        for col, lags in config[\"lag\"].items():\n",
    "            df = add_lag_features(df, col, lags)\n",
    "\n",
    "    # Add rolling averages\n",
    "    if \"rolling_avg\" in config:\n",
    "        for col, windows in config[\"rolling_avg\"].items():\n",
    "            df = add_rolling_avg_features(df, col, windows)\n",
    "\n",
    "    # Add time features if the flag is True\n",
    "    if config.get(\"add_time_features\", False):\n",
    "        df = add_time_features(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed24233",
   "metadata": {},
   "source": [
    "## Data Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75f3712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataManager:\n",
    "    def __init__(self, config={\"lag\": [1, 2, 3], \"rolling_avg\": [3, 6, 12], \"add_time_features\": True}):\n",
    "        plain_data = lf.load_all_data()\n",
    "        # List of column names\n",
    "        self.stations = [f\"station_{i}\" for i in range(1, 12)]\n",
    "        self.zones = [f\"zone_{i}\" for i in range(1, 21)]\n",
    "\n",
    "        # Configuration for engineered features\n",
    "        full_config = {\n",
    "            \"lag\": {col: config[\"lag\"] for col in self.stations},  # Lags for all station columns\n",
    "            \"rolling_avg\": {col: config[\"rolling_avg\"] for col in self.stations},  # Rolling averages\n",
    "            \"add_time_features\": config[\"add_time_features\"],  # Turn time-based features on/off\n",
    "        }\n",
    "\n",
    "        self.data = add_engineered_features(plain_data, full_config, standardize_columns=self.stations)\n",
    "        self.engineereds = self.data.columns.difference(self.stations + self.zones).tolist()\n",
    "    \n",
    "    def out_data(self, zone=None, plain=False):\n",
    "        return_cols = self.stations\n",
    "        if zone == None:\n",
    "            return_cols = self.zones + return_cols\n",
    "        elif isinstance(zone, str):\n",
    "            return_cols = zone + return_cols\n",
    "        elif isinstance(zone, int):\n",
    "            return_cols = [f'zone_{zone}'] + return_cols\n",
    "        else:\n",
    "            raise TypeError\n",
    "        if not plain:\n",
    "            return_cols += self.engineereds\n",
    "        return self.data[return_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22572fd",
   "metadata": {},
   "source": [
    "## Preprocessers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab1cf266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, sequence_length):  # For LSTM CNN\n",
    "    # Get the total number of sequences\n",
    "    num_sequences = len(data) - sequence_length\n",
    "    \n",
    "    # Pre-allocate arrays for X and y\n",
    "    X = np.empty((num_sequences, sequence_length, data.shape[1] - 1))  # Exclude response column\n",
    "    y = np.empty(num_sequences)\n",
    "    \n",
    "    # Fill in the X and y arrays\n",
    "    with tqdm(total=num_sequences, desc=f'Slicing Sequences of Length {sequence_length} ðŸ’…ðŸ”ª', colour='purple') as pbar:\n",
    "        for i in range(num_sequences):\n",
    "            X[i] = data.iloc[i:i + sequence_length, 1:].values  # Predictors\n",
    "            y[i] = data.iloc[i + sequence_length, 0]  # Response\n",
    "            pbar.update(1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6912ff91",
   "metadata": {},
   "source": [
    "# Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "555e7d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cnn(sequence_length, feature_dim):\n",
    "    # define shape of input\n",
    "    input_shape = (sequence_length, feature_dim)\n",
    "    \n",
    "    # construct input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # construct CNN layers\n",
    "    cnn = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "    cnn = MaxPooling1D(pool_size=2)(cnn)\n",
    "    cnn = Flatten()(cnn)\n",
    "\n",
    "    # Define a Lambda layer to reshape the CNN output for LSTM\n",
    "    lstm_input = Lambda(lambda x: tf.expand_dims(x, axis=1))(cnn)\n",
    "    \n",
    "    # construct LSTM layers\n",
    "    lstm = LSTM(64, return_sequences=False)(lstm_input)\n",
    "\n",
    "    # Fully connected layers\n",
    "    dense = Dense(128, activation='relu')(lstm)\n",
    "    dense = Dropout(0.5)(dense)\n",
    "    outputs = Dense(1, activation='sigmoid')(dense)  # For binary classification\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Return\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c9fe52",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eed70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom expanding window splitter\n",
    "class ExpandingWindowSplit(BaseCrossValidator):\n",
    "    def __init__(self, n_splits=5):\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = X.shape[0]\n",
    "        fold_size = n_samples // (self.n_splits + 1)\n",
    "        for i in range(1, self.n_splits + 1):\n",
    "            train_end = i * fold_size\n",
    "            test_start = train_end\n",
    "            test_end = test_start + fold_size\n",
    "\n",
    "            train_indices = list(range(0, train_end))\n",
    "            test_indices = list(range(test_start, test_end))\n",
    "\n",
    "            yield train_indices, test_indices\n",
    "\n",
    "    def _iter_test_indices(self, X=None, y=None, groups=None):\n",
    "        n_samples = X.shape[0]\n",
    "        fold_size = n_samples // (self.n_splits + 1)\n",
    "        for i in range(1, self.n_splits + 1):\n",
    "            test_start = i * fold_size\n",
    "            test_end = test_start + fold_size\n",
    "            yield range(test_start, test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d4a3bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "d = dataManager()\n",
    "data = d.out_data(1)\n",
    "\n",
    "# Prepare the model and parameter grid\n",
    "model = XGBRegressor(objective=\"reg:squarederror\")\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "    \"max_depth\": [3, 5, 7, 9],\n",
    "    \"n_estimators\": [50, 100, 150, 200]\n",
    "}\n",
    "\n",
    "# Define GridSearchCV with the custom cross-validator\n",
    "cv = ExpandingWindowSplit(n_splits=5)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring=\"neg_root_mean_squared_error\", verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2041f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "[CV] END ...learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.8s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.9s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.8s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=150; total time=   1.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=150; total time=   1.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END ...learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END ...learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.8s\n",
      "[CV] END ...learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.8s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   1.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   1.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   1.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=150; total time=   1.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=150; total time=   1.6s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=150; total time=   1.8s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=150; total time=   1.8s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=150; total time=   2.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   2.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   2.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   2.7s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   3.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   2.9s\n",
      "[CV] END ...learning_rate=0.01, max_depth=9, n_estimators=50; total time=   1.3s\n",
      "[CV] END ...learning_rate=0.01, max_depth=9, n_estimators=50; total time=   1.5s\n",
      "[CV] END ...learning_rate=0.01, max_depth=9, n_estimators=50; total time=   1.5s\n",
      "[CV] END ...learning_rate=0.01, max_depth=9, n_estimators=50; total time=   1.5s\n",
      "[CV] END ...learning_rate=0.01, max_depth=9, n_estimators=50; total time=   1.6s\n",
      "[CV] END ..learning_rate=0.01, max_depth=9, n_estimators=100; total time=   1.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=9, n_estimators=100; total time=   2.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=9, n_estimators=100; total time=   2.7s\n",
      "[CV] END ..learning_rate=0.01, max_depth=9, n_estimators=100; total time=   2.8s\n",
      "[CV] END ..learning_rate=0.01, max_depth=9, n_estimators=100; total time=   3.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=9, n_estimators=150; total time=   2.8s\n",
      "[CV] END ..learning_rate=0.01, max_depth=9, n_estimators=150; total time=   3.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=9, n_estimators=150; total time=   4.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=9, n_estimators=150; total time=   4.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=9, n_estimators=150; total time=   4.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=9, n_estimators=200; total time=   4.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=9, n_estimators=200; total time=   5.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=9, n_estimators=200; total time=   5.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=9, n_estimators=200; total time=   5.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=9, n_estimators=200; total time=   5.8s\n",
      "[CV] END ...learning_rate=0.05, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.05, max_depth=3, n_estimators=50; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.05, max_depth=3, n_estimators=50; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.05, max_depth=3, n_estimators=50; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.05, max_depth=3, n_estimators=50; total time=   0.8s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=100; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=100; total time=   0.8s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=150; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=150; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=150; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=150; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=150; total time=   0.9s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=200; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=200; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=200; total time=   0.9s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=200; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.05, max_depth=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.05, max_depth=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.05, max_depth=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.05, max_depth=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.05, max_depth=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=150; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=150; total time=   0.9s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=150; total time=   1.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=150; total time=   1.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=150; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=200; total time=   1.9s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=200; total time=   1.9s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END ...learning_rate=0.05, max_depth=7, n_estimators=50; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.05, max_depth=7, n_estimators=50; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.05, max_depth=7, n_estimators=50; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.05, max_depth=7, n_estimators=50; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.05, max_depth=7, n_estimators=50; total time=   0.9s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=100; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=100; total time=   1.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=100; total time=   1.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=100; total time=   1.5s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=100; total time=   1.7s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=150; total time=   1.5s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=150; total time=   1.7s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=150; total time=   2.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=150; total time=   2.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=150; total time=   2.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=200; total time=   1.8s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=200; total time=   2.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=200; total time=   2.5s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=200; total time=   2.8s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=200; total time=   2.9s\n",
      "[CV] END ...learning_rate=0.05, max_depth=9, n_estimators=50; total time=   1.3s\n",
      "[CV] END ...learning_rate=0.05, max_depth=9, n_estimators=50; total time=   1.6s\n",
      "[CV] END ...learning_rate=0.05, max_depth=9, n_estimators=50; total time=   1.7s\n",
      "[CV] END ...learning_rate=0.05, max_depth=9, n_estimators=50; total time=   1.7s\n",
      "[CV] END ...learning_rate=0.05, max_depth=9, n_estimators=50; total time=   1.9s\n",
      "[CV] END ..learning_rate=0.05, max_depth=9, n_estimators=100; total time=   2.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=9, n_estimators=100; total time=   2.8s\n",
      "[CV] END ..learning_rate=0.05, max_depth=9, n_estimators=100; total time=   2.9s\n",
      "[CV] END ..learning_rate=0.05, max_depth=9, n_estimators=100; total time=   3.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=9, n_estimators=100; total time=   3.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=9, n_estimators=150; total time=   3.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=9, n_estimators=150; total time=   3.8s\n",
      "[CV] END ..learning_rate=0.05, max_depth=9, n_estimators=150; total time=   4.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=9, n_estimators=150; total time=   4.7s\n",
      "[CV] END ..learning_rate=0.05, max_depth=9, n_estimators=150; total time=   4.6s\n",
      "[CV] END ..learning_rate=0.05, max_depth=9, n_estimators=200; total time=   3.6s\n",
      "[CV] END ..learning_rate=0.05, max_depth=9, n_estimators=200; total time=   4.6s\n",
      "[CV] END ..learning_rate=0.05, max_depth=9, n_estimators=200; total time=   4.8s\n",
      "[CV] END ..learning_rate=0.05, max_depth=9, n_estimators=200; total time=   5.5s\n",
      "[CV] END ..learning_rate=0.05, max_depth=9, n_estimators=200; total time=   6.0s\n",
      "[CV] END ....learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END ....learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.3s\n",
      "[CV] END ....learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.4s\n",
      "[CV] END ....learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.4s\n",
      "[CV] END ....learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.9s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=150; total time=   0.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=150; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=150; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=150; total time=   1.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=150; total time=   1.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   1.7s\n",
      "[CV] END ....learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END ....learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.8s\n",
      "[CV] END ....learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.9s\n",
      "[CV] END ....learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.9s\n",
      "[CV] END ....learning_rate=0.1, max_depth=7, n_estimators=50; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   1.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   1.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   1.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   1.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=150; total time=   1.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=150; total time=   1.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=150; total time=   2.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=150; total time=   1.9s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=150; total time=   2.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   1.9s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   2.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   2.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   2.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   2.9s\n",
      "[CV] END ....learning_rate=0.1, max_depth=9, n_estimators=50; total time=   1.2s\n",
      "[CV] END ....learning_rate=0.1, max_depth=9, n_estimators=50; total time=   1.4s\n",
      "[CV] END ....learning_rate=0.1, max_depth=9, n_estimators=50; total time=   1.5s\n",
      "[CV] END ....learning_rate=0.1, max_depth=9, n_estimators=50; total time=   1.6s\n",
      "[CV] END ....learning_rate=0.1, max_depth=9, n_estimators=50; total time=   1.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=9, n_estimators=100; total time=   1.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=9, n_estimators=100; total time=   3.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=9, n_estimators=100; total time=   3.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=9, n_estimators=100; total time=   2.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=9, n_estimators=100; total time=   3.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=9, n_estimators=150; total time=   2.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=9, n_estimators=150; total time=   3.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=9, n_estimators=150; total time=   3.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=9, n_estimators=150; total time=   3.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=9, n_estimators=150; total time=   4.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=9, n_estimators=200; total time=   3.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=9, n_estimators=200; total time=   4.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=9, n_estimators=200; total time=   4.9s\n",
      "[CV] END ...learning_rate=0.1, max_depth=9, n_estimators=200; total time=   4.9s\n",
      "[CV] END ...learning_rate=0.1, max_depth=9, n_estimators=200; total time=   5.2s\n",
      "[CV] END ....learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.3s\n",
      "[CV] END ....learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.3s\n",
      "[CV] END ....learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.4s\n",
      "[CV] END ....learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.4s\n",
      "[CV] END ....learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.7s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.7s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.8s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.8s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.9s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=200; total time=   1.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END ....learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END ....learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END ....learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END ....learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=150; total time=   0.9s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=150; total time=   1.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=150; total time=   1.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=150; total time=   1.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=150; total time=   1.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=200; total time=   1.7s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=200; total time=   1.6s\n",
      "[CV] END ....learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END ....learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.7s\n",
      "[CV] END ....learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.8s\n",
      "[CV] END ....learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.9s\n",
      "[CV] END ....learning_rate=0.2, max_depth=7, n_estimators=50; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=100; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=100; total time=   1.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=100; total time=   1.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=100; total time=   1.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=100; total time=   1.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=150; total time=   1.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=150; total time=   1.7s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=150; total time=   1.9s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=150; total time=   2.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=150; total time=   2.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=200; total time=   1.7s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=200; total time=   2.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=200; total time=   2.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=200; total time=   2.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=200; total time=   2.5s\n",
      "[CV] END ....learning_rate=0.2, max_depth=9, n_estimators=50; total time=   1.2s\n",
      "[CV] END ....learning_rate=0.2, max_depth=9, n_estimators=50; total time=   1.4s\n",
      "[CV] END ....learning_rate=0.2, max_depth=9, n_estimators=50; total time=   1.5s\n",
      "[CV] END ....learning_rate=0.2, max_depth=9, n_estimators=50; total time=   1.6s\n",
      "[CV] END ....learning_rate=0.2, max_depth=9, n_estimators=50; total time=   1.8s\n",
      "[CV] END ...learning_rate=0.2, max_depth=9, n_estimators=100; total time=   2.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=9, n_estimators=100; total time=   2.7s\n",
      "[CV] END ...learning_rate=0.2, max_depth=9, n_estimators=100; total time=   2.6s\n",
      "[CV] END ...learning_rate=0.2, max_depth=9, n_estimators=100; total time=   3.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=9, n_estimators=100; total time=   4.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=9, n_estimators=150; total time=   2.7s\n",
      "[CV] END ...learning_rate=0.2, max_depth=9, n_estimators=150; total time=   3.7s\n",
      "[CV] END ...learning_rate=0.2, max_depth=9, n_estimators=150; total time=   3.7s\n",
      "[CV] END ...learning_rate=0.2, max_depth=9, n_estimators=150; total time=   3.7s\n",
      "[CV] END ...learning_rate=0.2, max_depth=9, n_estimators=150; total time=   3.6s\n",
      "[CV] END ...learning_rate=0.2, max_depth=9, n_estimators=200; total time=   3.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=9, n_estimators=200; total time=   3.7s\n",
      "[CV] END ...learning_rate=0.2, max_depth=9, n_estimators=200; total time=   4.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=9, n_estimators=200; total time=   4.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=9, n_estimators=200; total time=   4.4s\n",
      "{'mean_fit_time': array([0.25818267, 0.37529278, 0.47699575, 0.67066116, 0.42728777,\n",
      "       0.67067637, 0.86339025, 1.13713665, 0.68113003, 1.1815207 ,\n",
      "       1.70435185, 2.63753972, 1.45387158, 2.55517077, 3.86458764,\n",
      "       5.13217883, 0.38880119, 0.49095497, 0.62768655, 0.71489153,\n",
      "       0.52507787, 0.74095602, 0.99058366, 1.77719564, 0.94329081,\n",
      "       1.33406777, 1.9211544 , 2.38965163, 1.60068197, 2.86045876,\n",
      "       3.99576039, 4.85149322, 0.3267612 , 0.44670324, 0.56280532,\n",
      "       0.63572869, 0.48443923, 0.71548743, 0.99039798, 1.24881201,\n",
      "       0.83845553, 1.35392742, 1.89242487, 2.33271828, 1.46434121,\n",
      "       2.74098654, 3.54026179, 4.51353245, 0.35845456, 0.46809216,\n",
      "       0.52303882, 0.76097994, 0.4147613 , 0.74846992, 1.06537981,\n",
      "       1.38411894, 0.78667378, 1.18650069, 1.76897144, 2.18818464,\n",
      "       1.45945153, 2.8971314 , 3.42477307, 3.85017385]), 'std_fit_time': array([0.0717759 , 0.09682479, 0.12955156, 0.14204143, 0.07103306,\n",
      "       0.14638749, 0.16663467, 0.21871518, 0.09359927, 0.17278153,\n",
      "       0.17704227, 0.2997765 , 0.11295308, 0.40794455, 0.57722236,\n",
      "       0.61947271, 0.1906557 , 0.15428312, 0.1285267 , 0.15951016,\n",
      "       0.13823001, 0.13717985, 0.18601433, 0.800248  , 0.02595892,\n",
      "       0.19629438, 0.30416229, 0.4063436 , 0.18027361, 0.39859639,\n",
      "       0.58395203, 0.80396796, 0.08650851, 0.0994948 , 0.12310566,\n",
      "       0.14644983, 0.12874689, 0.15115696, 0.2137498 , 0.24797968,\n",
      "       0.12270737, 0.22640159, 0.25223925, 0.33638913, 0.18087288,\n",
      "       0.50776749, 0.60324248, 0.56694169, 0.09383608, 0.12803342,\n",
      "       0.10904381, 0.16270365, 0.07746165, 0.24403207, 0.12991486,\n",
      "       0.20905703, 0.1218998 , 0.16599837, 0.24640625, 0.29909217,\n",
      "       0.21194268, 0.70063047, 0.38839404, 0.48408352]), 'mean_score_time': array([0.02713962, 0.02689714, 0.03061152, 0.0363245 , 0.032305  ,\n",
      "       0.0370893 , 0.03674788, 0.03765721, 0.03432693, 0.03778481,\n",
      "       0.03907094, 0.04639688, 0.03798676, 0.03879042, 0.04394841,\n",
      "       0.04631214, 0.03744373, 0.03543   , 0.03699317, 0.03602362,\n",
      "       0.03906736, 0.05666385, 0.03776689, 0.05591936, 0.04042559,\n",
      "       0.03821802, 0.04282589, 0.04431009, 0.03833656, 0.0412684 ,\n",
      "       0.04403   , 0.04366121, 0.03682947, 0.03667574, 0.03570004,\n",
      "       0.03661537, 0.03680735, 0.03579459, 0.03846169, 0.04241595,\n",
      "       0.03667068, 0.03898411, 0.03946266, 0.04466081, 0.03619962,\n",
      "       0.04255428, 0.0430388 , 0.04887142, 0.03666615, 0.03560147,\n",
      "       0.03485317, 0.03737311, 0.03171511, 0.03753877, 0.04046631,\n",
      "       0.04590263, 0.03619156, 0.03932028, 0.04612794, 0.04568114,\n",
      "       0.03873062, 0.04460402, 0.04910412, 0.04685206]), 'std_score_time': array([0.0010774 , 0.00022177, 0.0030649 , 0.00224846, 0.00188558,\n",
      "       0.00308376, 0.00319773, 0.00164952, 0.00262525, 0.00310026,\n",
      "       0.00129263, 0.00689669, 0.00359943, 0.00195329, 0.0042609 ,\n",
      "       0.00250018, 0.00346609, 0.00319794, 0.00320214, 0.00283998,\n",
      "       0.00494924, 0.03898048, 0.00228136, 0.01302355, 0.00409647,\n",
      "       0.00295359, 0.0028148 , 0.00352479, 0.00230779, 0.00344846,\n",
      "       0.00261019, 0.00177355, 0.00394749, 0.00520968, 0.00250656,\n",
      "       0.00289355, 0.00461104, 0.00244985, 0.00407976, 0.00294995,\n",
      "       0.00251955, 0.00303571, 0.00352222, 0.00416302, 0.00269904,\n",
      "       0.00551132, 0.00192315, 0.00421648, 0.00328636, 0.00437016,\n",
      "       0.00289599, 0.00533377, 0.00151413, 0.00372236, 0.00320143,\n",
      "       0.00443485, 0.00452578, 0.0042575 , 0.0107984 , 0.00345451,\n",
      "       0.00274518, 0.00678621, 0.00640599, 0.00251438]), 'param_learning_rate': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value=1e+20), 'param_max_depth': masked_array(data=[3, 3, 3, 3, 5, 5, 5, 5, 7, 7, 7, 7, 9, 9, 9, 9, 3, 3,\n",
      "                   3, 3, 5, 5, 5, 5, 7, 7, 7, 7, 9, 9, 9, 9, 3, 3, 3, 3,\n",
      "                   5, 5, 5, 5, 7, 7, 7, 7, 9, 9, 9, 9, 3, 3, 3, 3, 5, 5,\n",
      "                   5, 5, 7, 7, 7, 7, 9, 9, 9, 9],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value=999999), 'param_n_estimators': masked_array(data=[50, 100, 150, 200, 50, 100, 150, 200, 50, 100, 150,\n",
      "                   200, 50, 100, 150, 200, 50, 100, 150, 200, 50, 100,\n",
      "                   150, 200, 50, 100, 150, 200, 50, 100, 150, 200, 50,\n",
      "                   100, 150, 200, 50, 100, 150, 200, 50, 100, 150, 200,\n",
      "                   50, 100, 150, 200, 50, 100, 150, 200, 50, 100, 150,\n",
      "                   200, 50, 100, 150, 200, 50, 100, 150, 200],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value=999999), 'params': [{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}, {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 150}, {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50}, {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 150}, {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50}, {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100}, {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 150}, {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200}, {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 50}, {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 100}, {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 150}, {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 200}, {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 50}, {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 150}, {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 50}, {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 150}, {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 50}, {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 100}, {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 150}, {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200}, {'learning_rate': 0.05, 'max_depth': 9, 'n_estimators': 50}, {'learning_rate': 0.05, 'max_depth': 9, 'n_estimators': 100}, {'learning_rate': 0.05, 'max_depth': 9, 'n_estimators': 150}, {'learning_rate': 0.05, 'max_depth': 9, 'n_estimators': 200}, {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}, {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 150}, {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}, {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 150}, {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50}, {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}, {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 150}, {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}, {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50}, {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100}, {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 150}, {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 200}, {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 50}, {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 150}, {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 50}, {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 150}, {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 50}, {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 100}, {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 150}, {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200}, {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 50}, {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 100}, {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 150}, {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 200}], 'split0_test_score': array([-3931.77860737, -3194.40322709, -2763.6878696 , -2524.1132893 ,\n",
      "       -3703.24372568, -2840.51134136, -2411.97888334, -2191.83881939,\n",
      "       -3642.66094198, -2744.17128372, -2283.32845435, -2048.48507127,\n",
      "       -3618.52256312, -2714.49881466, -2251.45900649, -2025.07332531,\n",
      "       -2361.49166071, -2092.05422496, -2057.74141267, -2035.57827839,\n",
      "       -2033.70700785, -1917.57385092, -1926.0491304 , -1925.45794772,\n",
      "       -1908.84800432, -1833.51223581, -1854.72946534, -1853.0568146 ,\n",
      "       -1925.56967803, -1836.25317724, -1851.26892596, -1856.98442662,\n",
      "       -2092.68123535, -2025.14456905, -1999.81358657, -1967.89574136,\n",
      "       -1917.47499849, -1946.49723375, -1927.59016084, -1916.86032936,\n",
      "       -1869.19454186, -1881.54825228, -1872.71064947, -1865.10845575,\n",
      "       -1842.62561228, -1853.75919155, -1859.75867837, -1858.26960202,\n",
      "       -2018.45728386, -1958.52257297, -1989.1530918 , -1986.95719411,\n",
      "       -1872.91340375, -1858.95394209, -1851.06318836, -1847.62612312,\n",
      "       -1905.01012574, -1896.4810259 , -1889.51920973, -1893.05029223,\n",
      "       -1885.88795311, -1888.71830332, -1886.84489938, -1886.13873631]), 'split1_test_score': array([-4358.26853426, -3538.40577087, -3047.55370627, -2747.70112751,\n",
      "       -4037.17086253, -3055.0279786 , -2501.58474059, -2188.82712841,\n",
      "       -3937.65659111, -2895.99642225, -2321.57941903, -2002.22230756,\n",
      "       -3913.82350688, -2854.943258  , -2271.76132038, -1957.89171447,\n",
      "       -2531.97446744, -2043.89402469, -1857.30310601, -1800.20618266,\n",
      "       -2012.87646997, -1711.16719558, -1673.20741037, -1658.1120071 ,\n",
      "       -1827.98689874, -1633.75103197, -1625.82655227, -1624.5016348 ,\n",
      "       -1793.14947295, -1633.2651158 , -1618.81790021, -1618.22687944,\n",
      "       -2064.58258427, -1827.13214493, -1731.96193134, -1689.95601769,\n",
      "       -1718.25736133, -1659.70876701, -1650.53417304, -1652.40006395,\n",
      "       -1638.54249282, -1632.55966776, -1632.27221567, -1632.00031007,\n",
      "       -1630.11633656, -1622.00755321, -1622.30537422, -1624.32109233,\n",
      "       -1796.47088774, -1690.25944977, -1674.76959838, -1684.24091262,\n",
      "       -1710.81091872, -1685.13652046, -1691.83278544, -1697.35216311,\n",
      "       -1644.49921826, -1643.97375964, -1650.08448176, -1652.50231983,\n",
      "       -1649.77078983, -1651.31638796, -1652.36478671, -1651.83638149]), 'split2_test_score': array([-4248.82229891, -3424.82814637, -2952.43984748, -2647.81065135,\n",
      "       -3966.93448228, -3043.74799105, -2541.12752424, -2256.10221491,\n",
      "       -3853.59464185, -2864.91515945, -2337.88618697, -2056.73260111,\n",
      "       -3801.06586057, -2779.10998616, -2236.86112191, -1957.25490655,\n",
      "       -2446.44801312, -2073.81561462, -1973.49180622, -1972.39456484,\n",
      "       -2073.69097391, -1776.75120145, -1725.55014372, -1719.55196734,\n",
      "       -1889.16471111, -1642.92797364, -1594.83239892, -1580.14085624,\n",
      "       -1797.55565457, -1623.2496254 , -1591.35158902, -1582.16700369,\n",
      "       -2091.28016222, -2045.10547254, -1960.27385046, -1911.34590315,\n",
      "       -1804.48471685, -1744.00644473, -1707.84837055, -1694.31586766,\n",
      "       -1647.27087192, -1592.45408959, -1577.23037177, -1575.63336663,\n",
      "       -1629.16251711, -1595.05320035, -1591.18205581, -1589.83795518,\n",
      "       -1833.52509378, -1765.93525703, -1704.08421834, -1666.91092449,\n",
      "       -1706.08803348, -1660.2034625 , -1656.70378215, -1666.61053251,\n",
      "       -1657.14261127, -1645.64896997, -1641.13231301, -1630.37963176,\n",
      "       -1636.07594087, -1636.65781617, -1638.37667042, -1638.27881611]), 'split3_test_score': array([-5301.98892328, -4265.65551649, -3670.52830486, -3311.59935354,\n",
      "       -5078.50256822, -3906.25430083, -3235.45846423, -2835.48713855,\n",
      "       -5016.17692874, -3809.42513094, -3106.33144697, -2698.57256467,\n",
      "       -4991.2327603 , -3766.78756187, -3054.34976492, -2642.61379178,\n",
      "       -3097.00871322, -2519.17344347, -2272.07309285, -2123.39987167,\n",
      "       -2558.82238646, -2085.88768388, -1924.21274898, -1877.3025883 ,\n",
      "       -2418.68684236, -2028.5466874 , -1981.31556523, -1960.09743575,\n",
      "       -2382.36248117, -2027.13894504, -1961.85929098, -1955.74483491,\n",
      "       -2565.75303264, -2147.86455666, -2010.58933954, -1941.77343285,\n",
      "       -2115.14920176, -1897.65670436, -1851.2291209 , -1864.47337757,\n",
      "       -2030.36535306, -2020.02621401, -1992.54442227, -1993.25158258,\n",
      "       -2045.64140741, -2003.12271148, -2022.19618504, -2028.9840884 ,\n",
      "       -2152.29362143, -1973.69114596, -1907.28082913, -1854.93716729,\n",
      "       -1932.72535569, -1921.25692691, -1943.94728292, -1939.68505926,\n",
      "       -1942.96436123, -1933.936737  , -1925.47903545, -1923.42157147,\n",
      "       -2014.39479256, -2026.04312099, -2036.85786807, -2039.41668466]), 'split4_test_score': array([-4285.22482118, -3541.98479913, -3113.79075449, -2840.46436159,\n",
      "       -4039.77725236, -3125.66168531, -2611.99840008, -2323.57101995,\n",
      "       -3896.166727  , -2907.82917284, -2379.36810414, -2071.48332963,\n",
      "       -3837.81392165, -2819.32856905, -2271.63315388, -1968.21000254,\n",
      "       -2617.4987693 , -2160.86294841, -2006.8177467 , -1908.52198648,\n",
      "       -2115.83860783, -1777.06004931, -1656.92845858, -1613.00602506,\n",
      "       -1889.74844942, -1601.07745379, -1606.72563107, -1594.58021678,\n",
      "       -1797.73104647, -1609.67060144, -1579.19886628, -1569.74224633,\n",
      "       -2159.45868005, -1936.61883174, -1800.67696923, -1729.22481711,\n",
      "       -1746.58080243, -1622.8760981 , -1558.19853829, -1514.84652181,\n",
      "       -1612.63481937, -1599.4620721 , -1572.8663827 , -1559.40043257,\n",
      "       -1592.81773221, -1540.93298198, -1524.87532755, -1524.64678582,\n",
      "       -1859.91535474, -1692.64619853, -1616.65843798, -1572.40031402,\n",
      "       -1756.90190608, -1657.98702594, -1636.39233148, -1616.62812167,\n",
      "       -1681.71361398, -1648.5247043 , -1632.19587747, -1627.27041252,\n",
      "       -1560.10134748, -1541.53214023, -1535.12930402, -1533.94435868]), 'mean_test_score': array([-4425.216637  , -3593.05549199, -3109.60009654, -2814.33775666,\n",
      "       -4165.12577821, -3194.24065943, -2660.4296025 , -2359.16526424,\n",
      "       -4069.25116614, -3044.46743384, -2485.69872229, -2175.49917485,\n",
      "       -4032.4917225 , -2986.93363795, -2417.21287352, -2110.20874813,\n",
      "       -2610.88432476, -2177.96005123, -2033.48543289, -1968.02017681,\n",
      "       -2158.9870892 , -1853.68799623, -1781.18957841, -1758.6861071 ,\n",
      "       -1986.88698119, -1747.96307652, -1732.68592257, -1722.47539163,\n",
      "       -1939.27366664, -1745.91549298, -1720.49931449, -1716.5730782 ,\n",
      "       -2194.75113891, -1996.37311498, -1900.66313543, -1848.03918244,\n",
      "       -1860.38941617, -1774.14904959, -1739.08007272, -1728.57923207,\n",
      "       -1759.6016158 , -1745.21005915, -1729.52480838, -1725.07882952,\n",
      "       -1748.07272112, -1722.97512771, -1724.0635242 , -1725.21190475,\n",
      "       -1932.13244831, -1816.21092485, -1778.38923513, -1753.08930251,\n",
      "       -1795.88792354, -1756.70757558, -1755.98787407, -1753.58039993,\n",
      "       -1766.2659861 , -1753.71303936, -1747.68218348, -1745.32484556,\n",
      "       -1749.24616477, -1748.85355373, -1749.91470572, -1749.92299545]), 'std_test_score': array([462.04013907, 359.22407179, 304.2572542 , 269.94579227,\n",
      "       473.06589269, 368.461435  , 294.68498743, 243.22199324,\n",
      "       484.23769183, 386.85675153, 311.84245893, 262.55971568,\n",
      "       489.10006412, 392.70764325, 318.83981125, 267.38069148,\n",
      "       257.61344646, 174.88193967, 136.28135388, 109.93421053,\n",
      "       203.00191895, 134.23962801, 119.69681561, 122.27185549,\n",
      "       217.61248799, 162.29477593, 156.84376913, 154.74553087,\n",
      "       227.15020806, 163.43024212, 156.42211558, 158.88029257,\n",
      "       188.12566207, 108.04200707, 113.07108326, 115.12305216,\n",
      "       144.52720785, 127.9427201 , 133.9009988 , 145.9971956 ,\n",
      "       163.82695589, 173.99942214, 171.39138072, 173.18880454,\n",
      "       172.99990124, 176.229937  , 187.07453153, 189.05730324,\n",
      "       133.61564083, 125.46894729, 143.83988436, 148.24473176,\n",
      "        91.08175888, 111.09636824, 120.53576637, 120.79804738,\n",
      "       129.88950102, 132.39971118, 131.10662511, 133.64619261,\n",
      "       171.72849783, 179.71074264, 183.94333103, 184.98297344]), 'rank_test_score': array([64, 60, 58, 55, 63, 59, 54, 50, 62, 57, 52, 47, 61, 56, 51, 45, 53,\n",
      "       48, 44, 41, 46, 36, 32, 27, 42, 16, 10,  3, 40, 14,  2,  1, 49, 43,\n",
      "       38, 35, 37, 30, 11,  8, 28, 12,  9,  6, 17,  4,  5,  7, 39, 34, 31,\n",
      "       22, 33, 26, 25, 23, 29, 24, 15, 13, 19, 18, 20, 21], dtype=int32)}\n",
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 9, 'n_estimators': 200}\n",
      "Best RMSE: 1716.5730781982352\n"
     ]
    }
   ],
   "source": [
    "# Run GridSearch\n",
    "X = data.drop(columns=[\"zone_1\"])\n",
    "y = data[\"zone_1\"].astype(float)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best RMSE:\", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f28381d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.258183</td>\n",
       "      <td>0.071776</td>\n",
       "      <td>0.027140</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>-3931.778607</td>\n",
       "      <td>-4358.268534</td>\n",
       "      <td>-4248.822299</td>\n",
       "      <td>-5301.988923</td>\n",
       "      <td>-4285.224821</td>\n",
       "      <td>-4425.216637</td>\n",
       "      <td>462.040139</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.375293</td>\n",
       "      <td>0.096825</td>\n",
       "      <td>0.026897</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>-3194.403227</td>\n",
       "      <td>-3538.405771</td>\n",
       "      <td>-3424.828146</td>\n",
       "      <td>-4265.655516</td>\n",
       "      <td>-3541.984799</td>\n",
       "      <td>-3593.055492</td>\n",
       "      <td>359.224072</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.476996</td>\n",
       "      <td>0.129552</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>-2763.687870</td>\n",
       "      <td>-3047.553706</td>\n",
       "      <td>-2952.439847</td>\n",
       "      <td>-3670.528305</td>\n",
       "      <td>-3113.790754</td>\n",
       "      <td>-3109.600097</td>\n",
       "      <td>304.257254</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.670661</td>\n",
       "      <td>0.142041</td>\n",
       "      <td>0.036325</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>-2524.113289</td>\n",
       "      <td>-2747.701128</td>\n",
       "      <td>-2647.810651</td>\n",
       "      <td>-3311.599354</td>\n",
       "      <td>-2840.464362</td>\n",
       "      <td>-2814.337757</td>\n",
       "      <td>269.945792</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.427288</td>\n",
       "      <td>0.071033</td>\n",
       "      <td>0.032305</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>-3703.243726</td>\n",
       "      <td>-4037.170863</td>\n",
       "      <td>-3966.934482</td>\n",
       "      <td>-5078.502568</td>\n",
       "      <td>-4039.777252</td>\n",
       "      <td>-4165.125778</td>\n",
       "      <td>473.065893</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2.188185</td>\n",
       "      <td>0.299092</td>\n",
       "      <td>0.045681</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>0.20</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>-1893.050292</td>\n",
       "      <td>-1652.502320</td>\n",
       "      <td>-1630.379632</td>\n",
       "      <td>-1923.421571</td>\n",
       "      <td>-1627.270413</td>\n",
       "      <td>-1745.324846</td>\n",
       "      <td>133.646193</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.459452</td>\n",
       "      <td>0.211943</td>\n",
       "      <td>0.038731</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.20</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 9, 'n_esti...</td>\n",
       "      <td>-1885.887953</td>\n",
       "      <td>-1649.770790</td>\n",
       "      <td>-1636.075941</td>\n",
       "      <td>-2014.394793</td>\n",
       "      <td>-1560.101347</td>\n",
       "      <td>-1749.246165</td>\n",
       "      <td>171.728498</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2.897131</td>\n",
       "      <td>0.700630</td>\n",
       "      <td>0.044604</td>\n",
       "      <td>0.006786</td>\n",
       "      <td>0.20</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 9, 'n_esti...</td>\n",
       "      <td>-1888.718303</td>\n",
       "      <td>-1651.316388</td>\n",
       "      <td>-1636.657816</td>\n",
       "      <td>-2026.043121</td>\n",
       "      <td>-1541.532140</td>\n",
       "      <td>-1748.853554</td>\n",
       "      <td>179.710743</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>3.424773</td>\n",
       "      <td>0.388394</td>\n",
       "      <td>0.049104</td>\n",
       "      <td>0.006406</td>\n",
       "      <td>0.20</td>\n",
       "      <td>9</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 9, 'n_esti...</td>\n",
       "      <td>-1886.844899</td>\n",
       "      <td>-1652.364787</td>\n",
       "      <td>-1638.376670</td>\n",
       "      <td>-2036.857868</td>\n",
       "      <td>-1535.129304</td>\n",
       "      <td>-1749.914706</td>\n",
       "      <td>183.943331</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3.850174</td>\n",
       "      <td>0.484084</td>\n",
       "      <td>0.046852</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.20</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 9, 'n_esti...</td>\n",
       "      <td>-1886.138736</td>\n",
       "      <td>-1651.836381</td>\n",
       "      <td>-1638.278816</td>\n",
       "      <td>-2039.416685</td>\n",
       "      <td>-1533.944359</td>\n",
       "      <td>-1749.922995</td>\n",
       "      <td>184.982973</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.258183      0.071776         0.027140        0.001077   \n",
       "1        0.375293      0.096825         0.026897        0.000222   \n",
       "2        0.476996      0.129552         0.030612        0.003065   \n",
       "3        0.670661      0.142041         0.036325        0.002248   \n",
       "4        0.427288      0.071033         0.032305        0.001886   \n",
       "..            ...           ...              ...             ...   \n",
       "59       2.188185      0.299092         0.045681        0.003455   \n",
       "60       1.459452      0.211943         0.038731        0.002745   \n",
       "61       2.897131      0.700630         0.044604        0.006786   \n",
       "62       3.424773      0.388394         0.049104        0.006406   \n",
       "63       3.850174      0.484084         0.046852        0.002514   \n",
       "\n",
       "    param_learning_rate  param_max_depth  param_n_estimators  \\\n",
       "0                  0.01                3                  50   \n",
       "1                  0.01                3                 100   \n",
       "2                  0.01                3                 150   \n",
       "3                  0.01                3                 200   \n",
       "4                  0.01                5                  50   \n",
       "..                  ...              ...                 ...   \n",
       "59                 0.20                7                 200   \n",
       "60                 0.20                9                  50   \n",
       "61                 0.20                9                 100   \n",
       "62                 0.20                9                 150   \n",
       "63                 0.20                9                 200   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...       -3931.778607   \n",
       "1   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...       -3194.403227   \n",
       "2   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...       -2763.687870   \n",
       "3   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...       -2524.113289   \n",
       "4   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...       -3703.243726   \n",
       "..                                                ...                ...   \n",
       "59  {'learning_rate': 0.2, 'max_depth': 7, 'n_esti...       -1893.050292   \n",
       "60  {'learning_rate': 0.2, 'max_depth': 9, 'n_esti...       -1885.887953   \n",
       "61  {'learning_rate': 0.2, 'max_depth': 9, 'n_esti...       -1888.718303   \n",
       "62  {'learning_rate': 0.2, 'max_depth': 9, 'n_esti...       -1886.844899   \n",
       "63  {'learning_rate': 0.2, 'max_depth': 9, 'n_esti...       -1886.138736   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0        -4358.268534       -4248.822299       -5301.988923   \n",
       "1        -3538.405771       -3424.828146       -4265.655516   \n",
       "2        -3047.553706       -2952.439847       -3670.528305   \n",
       "3        -2747.701128       -2647.810651       -3311.599354   \n",
       "4        -4037.170863       -3966.934482       -5078.502568   \n",
       "..                ...                ...                ...   \n",
       "59       -1652.502320       -1630.379632       -1923.421571   \n",
       "60       -1649.770790       -1636.075941       -2014.394793   \n",
       "61       -1651.316388       -1636.657816       -2026.043121   \n",
       "62       -1652.364787       -1638.376670       -2036.857868   \n",
       "63       -1651.836381       -1638.278816       -2039.416685   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0        -4285.224821     -4425.216637      462.040139               64  \n",
       "1        -3541.984799     -3593.055492      359.224072               60  \n",
       "2        -3113.790754     -3109.600097      304.257254               58  \n",
       "3        -2840.464362     -2814.337757      269.945792               55  \n",
       "4        -4039.777252     -4165.125778      473.065893               63  \n",
       "..                ...              ...             ...              ...  \n",
       "59       -1627.270413     -1745.324846      133.646193               13  \n",
       "60       -1560.101347     -1749.246165      171.728498               19  \n",
       "61       -1541.532140     -1748.853554      179.710743               18  \n",
       "62       -1535.129304     -1749.914706      183.943331               20  \n",
       "63       -1533.944359     -1749.922995      184.982973               21  \n",
       "\n",
       "[64 rows x 16 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa107adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "d = dataManager()\n",
    "data = d.out_data(1)\n",
    "\n",
    "# Define the model\n",
    "gbr = GradientBoostingRegressor()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"subsample\": [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Define scoring function (RMSE)\n",
    "scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "# Use your ExpandingWindowSplit or any cross-validator\n",
    "cv = ExpandingWindowSplit(n_splits=5)\n",
    "\n",
    "# Split Data\n",
    "X = data.drop(columns=[\"zone_1\"])\n",
    "y = data[\"zone_1\"].astype(float)\n",
    "\n",
    "# GridSearchCV setup\n",
    "grid_search = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=cv, scoring=scorer, verbose=2)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best RMSE:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4affe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc39a901c9b847c0bec591aa87262fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid Search Progress:   0%|          | 0/729 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare data\n",
    "d = dataManager()\n",
    "data = d.out_data(1)\n",
    "\n",
    "# Split Data\n",
    "X = data.drop(columns=[\"zone_1\"])\n",
    "y = data[\"zone_1\"].astype(float)\n",
    "\n",
    "cv = ExpandingWindowSplit(n_splits=5)\n",
    "\n",
    "# Prepare the parameter grid\n",
    "param_grid = {\n",
    "    \"min_child_weight\": [1, 3, 5],           # Minimum sum of instance weights (regularization)\n",
    "    \"subsample\": [0.7, 0.8, 1.0],            # Fraction of samples for training each tree\n",
    "    \"colsample_bytree\": [0.7, 0.8, 1.0],     # Fraction of features for each tree\n",
    "    \"gamma\": [0, 0.1, 0.2],                  # Minimum loss reduction to make a split\n",
    "    \"reg_alpha\": [0, 0.01, 0.1],             # L1 regularization (sparsity control)\n",
    "    \"reg_lambda\": [1, 2, 5],                 # L2 regularization (ridge-style control)\n",
    "}\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "# Initialize tracking\n",
    "best_params = None\n",
    "best_score = np.inf  # RMSE should be minimized\n",
    "\n",
    "# Custom progress bar\n",
    "progress_bar = tqdm(grid, desc=\"Grid Search Progress\", colour='pink', leave=True)\n",
    "\n",
    "# Manual grid search loop\n",
    "for params in progress_bar:\n",
    "    # Update the progress bar with current params\n",
    "    progress_bar.set_postfix(n_estimators=50, learning_rate=0.2, max_depth=3, params=params)\n",
    "\n",
    "    # Configure the model with current parameters\n",
    "    model = XGBRegressor(**params)\n",
    "\n",
    "    # Cross-validation (using your custom CV splitter)\n",
    "    scores = []\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        model.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "        preds = model.predict(X.iloc[test_idx])\n",
    "        scores.append(mean_squared_error(y.iloc[test_idx], preds, squared=False))\n",
    "    \n",
    "    # Average RMSE across folds\n",
    "    avg_score = np.mean(scores)\n",
    "    \n",
    "    # Update best score\n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params = params\n",
    "\n",
    "# Display results\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb11545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "d = dataManager()\n",
    "data = d.out_data(1)\n",
    "\n",
    "# Split Data\n",
    "X = data.drop(columns=[\"zone_1\"])\n",
    "y = data[\"zone_1\"].astype(float)\n",
    "\n",
    "cv = ExpandingWindowSplit(n_splits=5)\n",
    "\n",
    "# Prepare the parameter grid\n",
    "param_grid = {\n",
    "    \"min_child_weight\": [1, 3, 5],           # Minimum sum of instance weights (regularization)\n",
    "    \"subsample\": [0.7, 0.8, 1.0],            # Fraction of samples for training each tree\n",
    "    \"colsample_bytree\": [0.7, 0.8, 1.0],     # Fraction of features for each tree\n",
    "    \"gamma\": [0, 0.1, 0.2],                  # Minimum loss reduction to make a split\n",
    "    \"reg_alpha\": [0, 0.01, 0.1],             # L1 regularization (sparsity control)\n",
    "    \"reg_lambda\": [1, 2, 5],                 # L2 regularization (ridge-style control)\n",
    "}\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "# Initialize tracking\n",
    "best_params = None\n",
    "best_score = np.inf  # RMSE should be minimized\n",
    "\n",
    "# Custom progress bar\n",
    "progress_bar = tqdm(grid, desc=\"Grid Search Progress\", colour='pink', leave=True)\n",
    "\n",
    "# Manual grid search loop\n",
    "for params in progress_bar:\n",
    "    # Update the progress bar with current params\n",
    "    progress_bar.set_postfix(n_estimators=200, learning_rate=0.05, max_depth=9, params=params)\n",
    "\n",
    "    # Configure the model with current parameters\n",
    "    model = XGBRegressor(**params)\n",
    "\n",
    "    # Cross-validation (using your custom CV splitter)\n",
    "    scores = []\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        model.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "        preds = model.predict(X.iloc[test_idx])\n",
    "        scores.append(mean_squared_error(y.iloc[test_idx], preds, squared=False))\n",
    "    \n",
    "    # Average RMSE across folds\n",
    "    avg_score = np.mean(scores)\n",
    "    \n",
    "    # Update best score\n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params = params\n",
    "\n",
    "# Display results\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e432c46e",
   "metadata": {},
   "source": [
    "# LSTM stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99336a8",
   "metadata": {},
   "source": [
    "def lstm_cnn_cv(data, sequence_lengths, n_splits=5):\n",
    "    results = {}\n",
    "\n",
    "    num_models = len(sequence_lengths)\n",
    "    with tqdm(total=num_models, desc=f'cv on sequence_lengths: {sequence_lengths}', colour='pink') as pbar1:\n",
    "        for seq_len in sequence_lengths:\n",
    "            n = len(data)\n",
    "            fold_size = n // (n_splits + 1)\n",
    "            zone = 'zone_1'\n",
    "\n",
    "            opt_results = []\n",
    "\n",
    "            with tqdm(total=n_splits, desc=f'Validating {seq_len}', colour='pink') as pbar:\n",
    "                for i in range(1, n_splits + 1):\n",
    "                    train_end = i * fold_size\n",
    "                    test_start = train_end\n",
    "                    test_end = test_start + fold_size\n",
    "\n",
    "                    pbar.set_description(f'Validating [splitting data] {seq_len}')\n",
    "                    train = data.iloc[:train_end]\n",
    "                    test = data.iloc[test_start:test_end]\n",
    "\n",
    "                    # Preprocess the data after splitting (train/test separately)\n",
    "                    X_train, y_train = train.drop(columns=zone), train[zone]\n",
    "                    X_test, y_test = test.drop(columns=zone), test[zone]\n",
    "\n",
    "                    pbar.set_description(f'Validating [splitting training data] {seq_len}')\n",
    "                    X_train, y_train = create_sequences(train, seq_len)  # Pass preprocessing params\n",
    "                    pbar.set_description(f'Validating [splitting testing data] {seq_len}')\n",
    "                    X_test, y_test = create_sequences(test, seq_len)\n",
    "\n",
    "                    pbar.set_description(f'Validating [training model] {seq_len}')\n",
    "                    model = lstm_cnn(seq_len, 82)  # Pass model params to the model function\n",
    "                    model.fit(X_train, y_train, epochs=5, verbose=0)\n",
    "\n",
    "                    pbar.set_description(f'Validating [evaluating model] {seq_len}')\n",
    "                    predictions = model.predict(X_test, verbose=0)\n",
    "                    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "                    opt_results.append(rmse)\n",
    "                    pbar.update(1)\n",
    "                results[seq_len] = np.mean(opt_results)\n",
    "            pbar1.update(1)\n",
    "        pbar.set_description('Finished!')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25650ab6",
   "metadata": {},
   "source": [
    "d = dataManager()\n",
    "\n",
    "results = lstm_cnn_cv(d.out_data(1), [24])\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
